{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üå≤ Random Forest on MFCC Features ‚Üí ONNX Export\n",
    "**Dataset:** `mfcc_with_labels_balanced_2723_samples.csv`  \n",
    "**Task:** Binary classification (already balanced ‚Äî no extra resampling needed)  \n",
    "**Goal:** Train, evaluate, save model, then export to ONNX safely."
   ],
   "id": "title"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Install Dependencies"
   ],
   "id": "cell-install-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install skl2onnx for sklearn ‚Üí ONNX conversion\n",
    "!pip install -q skl2onnx onnxruntime"
   ],
   "id": "cell-install"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Upload Your Dataset\n",
    "Run this cell to upload `mfcc_with_labels_balanced_2723_samples.csv` from your computer."
   ],
   "id": "cell-upload-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # Upload: mfcc_with_labels_balanced_2723_samples.csv"
   ],
   "id": "cell-upload"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Load & Explore Data"
   ],
   "id": "cell-load-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('mfcc_with_labels_balanced_2723_samples.csv')\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "print('\\nLabel distribution:')\n",
    "print(df['label'].value_counts())\n",
    "print('\\nFirst 3 rows:')\n",
    "df.head(3)"
   ],
   "id": "cell-load"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Prepare Features & Labels"
   ],
   "id": "cell-prep-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(columns=['label']).values.astype(np.float32)\n",
    "y = df['label'].values\n",
    "\n",
    "# Train/val/test split: 70% / 15% / 15%\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f'Train: {X_train.shape[0]} | Val: {X_val.shape[0]} | Test: {X_test.shape[0]}')\n",
    "print(f'Features: {X_train.shape[1]}')"
   ],
   "id": "cell-prep"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Train Random Forest"
   ],
   "id": "cell-train-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,       # number of trees\n",
    "    max_depth=None,         # grow full trees (let it learn)\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',    # standard for classification\n",
    "    class_weight='balanced',# extra safety since data is balanced\n",
    "    random_state=42,\n",
    "    n_jobs=-1               # use all CPU cores\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print('‚úÖ Training complete!')"
   ],
   "id": "cell-train"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Evaluate the Model"
   ],
   "id": "cell-eval-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Validation Set ---\n",
    "y_val_pred = rf.predict(X_val)\n",
    "print('=== Validation Set ===')\n",
    "print(classification_report(y_val, y_val_pred, digits=4))\n",
    "\n",
    "# --- Test Set ---\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('=== Test Set ===')\n",
    "print(classification_report(y_test, y_test_pred, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Test Set Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150)\n",
    "plt.show()"
   ],
   "id": "cell-eval"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Feature Importance"
   ],
   "id": "cell-fi-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f'mfcc_{i}' for i in range(X_train.shape[1])]\n",
    "importances = pd.Series(rf.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "importances.plot(kind='bar')\n",
    "plt.title('Feature Importances')\n",
    "plt.ylabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importances.png', dpi=150)\n",
    "plt.show()\n",
    "print(importances.head(10))"
   ],
   "id": "cell-fi"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Save the Sklearn Model (Pickle)\n",
    "Always save the original sklearn model **before** ONNX conversion ‚Äî this is your safe backup."
   ],
   "id": "cell-save-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf, 'random_forest_mfcc.pkl')\n",
    "print('‚úÖ Sklearn model saved ‚Üí random_forest_mfcc.pkl')\n",
    "\n",
    "# Verify it loads correctly\n",
    "rf_loaded = joblib.load('random_forest_mfcc.pkl')\n",
    "assert (rf_loaded.predict(X_test) == y_test_pred).all(), 'Model integrity check FAILED!'\n",
    "print('‚úÖ Integrity check passed ‚Äî sklearn model is intact.')"
   ],
   "id": "cell-save"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Export to ONNX\n",
    "We use `skl2onnx` which converts the sklearn model to ONNX **without** modifying the original."
   ],
   "id": "cell-onnx-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# Reload fresh from disk just to be safe\n",
    "rf_for_export = joblib.load('random_forest_mfcc.pkl')\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "initial_type = [('mfcc_input', FloatTensorType([None, n_features]))]\n",
    "\n",
    "onnx_model = convert_sklearn(\n",
    "    rf_for_export,\n",
    "    initial_types=initial_type,\n",
    "    target_opset=17,   # opset 17 is widely supported\n",
    "    options={id(rf_for_export): {'zipmap': False}}  # output plain numpy arrays, not dicts\n",
    ")\n",
    "\n",
    "with open('random_forest_mfcc.onnx', 'wb') as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print('‚úÖ ONNX model saved ‚Üí random_forest_mfcc.onnx')"
   ],
   "id": "cell-onnx"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Validate ONNX Output Matches Sklearn\n",
    "This is the critical step ‚Äî confirms the ONNX model predicts **identically** to the original."
   ],
   "id": "cell-validate-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "sess = ort.InferenceSession('random_forest_mfcc.onnx')\n",
    "input_name = sess.get_inputs()[0].name\n",
    "\n",
    "# Run inference on test set\n",
    "onnx_preds = sess.run(None, {input_name: X_test.astype(np.float32)})\n",
    "onnx_labels = onnx_preds[0]          # predicted class\n",
    "onnx_probs  = onnx_preds[1]          # probabilities [N, 2]\n",
    "\n",
    "sklearn_labels = rf.predict(X_test)\n",
    "\n",
    "match = (onnx_labels == sklearn_labels).mean() * 100\n",
    "print(f'‚úÖ ONNX vs Sklearn agreement: {match:.2f}%')\n",
    "\n",
    "if match == 100.0:\n",
    "    print('üéâ Perfect match ‚Äî ONNX model is verified safe to deploy!')\n",
    "else:\n",
    "    print(f'‚ö†Ô∏è  {100-match:.2f}% mismatch ‚Äî check opset version or data types.')\n",
    "\n",
    "# Peek at ONNX outputs\n",
    "print('\\nSample ONNX output labels:', onnx_labels[:10])\n",
    "print('Sample ONNX probabilities:\\n', onnx_probs[:5].round(4))"
   ],
   "id": "cell-validate"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Download All Files"
   ],
   "id": "cell-download-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('random_forest_mfcc.pkl')       # Original sklearn model\n",
    "files.download('random_forest_mfcc.onnx')      # ONNX model for deployment\n",
    "files.download('confusion_matrix.png')         # Evaluation plots\n",
    "files.download('feature_importances.png')"
   ],
   "id": "cell-download"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ (Optional) Hyperparameter Tuning with RandomizedSearchCV\n",
    "Run this if you want to squeeze out extra performance ‚Äî takes a few minutes on Colab."
   ],
   "id": "cell-tune-md"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators':      [100, 200, 300, 500],\n",
    "    'max_depth':         [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf':  [1, 2, 4],\n",
    "    'max_features':      ['sqrt', 'log2', 0.5],\n",
    "}\n",
    "\n",
    "rf_search = RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    rf_search,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print('Best params:', search.best_params_)\n",
    "print('Best CV F1:', search.best_score_.round(4))\n",
    "\n",
    "best_rf = search.best_estimator_\n",
    "print('\\nTest set report with best model:')\n",
    "print(classification_report(y_test, best_rf.predict(X_test), digits=4))"
   ],
   "id": "cell-tune"
  }
 ]
}
